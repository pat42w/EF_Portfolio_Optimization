{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook steps through an example of using the efficient frontier to optmise a stock portfolio given price data \n",
    "\n",
    "Sources:\n",
    "Article :     [Portfolio Optimization through mean-variance analysis](https://www.machinelearningplus.com/machine-learning/portfolio-optimization-python-example/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import math\n",
    "from datetime import timedelta \n",
    "import operator\n",
    "from functools import reduce\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt import plotting\n",
    "import cvxpy as cp\n",
    "from joblib import Parallel, delayed\n",
    "import seaborn as sns\n",
    "import plotly.offline\n",
    "import DatabaseMainFnc as dmf\n",
    "pd.set_option('display.max_columns', 38)\n",
    "\n",
    "# Import libraries to fetch historical EUR/USD prices\n",
    "from datetime import datetime,timedelta\n",
    "from forex_python.converter import get_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'rates.csv'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dmf.gen_curr_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df = pd.read_csv('rates.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 USD       JPY       GBP\n",
       "2006-01-01  0.847673  0.007199  1.459215\n",
       "2006-01-02  0.845594  0.007165  1.456664\n",
       "2006-01-03  0.842105  0.007171  1.455075\n",
       "2006-01-04  0.827609  0.007133  1.453172\n",
       "2006-01-05  0.827267  0.007127  1.451800"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>USD</th>\n      <th>JPY</th>\n      <th>GBP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2006-01-01</th>\n      <td>0.847673</td>\n      <td>0.007199</td>\n      <td>1.459215</td>\n    </tr>\n    <tr>\n      <th>2006-01-02</th>\n      <td>0.845594</td>\n      <td>0.007165</td>\n      <td>1.456664</td>\n    </tr>\n    <tr>\n      <th>2006-01-03</th>\n      <td>0.842105</td>\n      <td>0.007171</td>\n      <td>1.455075</td>\n    </tr>\n    <tr>\n      <th>2006-01-04</th>\n      <td>0.827609</td>\n      <td>0.007133</td>\n      <td>1.453172</td>\n    </tr>\n    <tr>\n      <th>2006-01-05</th>\n      <td>0.827267</td>\n      <td>0.007127</td>\n      <td>1.451800</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "rates_df=rates_df.set_index(pd.DatetimeIndex(rates_df['Date'].values))\n",
    "rates_df.drop(columns=['Date'],axis=1, inplace=True)\n",
    "rates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Currency not supported\n"
     ]
    }
   ],
   "source": [
    "#list(rates_df.columns)\n",
    "input_curr = 'DOGE'\n",
    "\n",
    "if not input_curr in list(rates_df.columns):\n",
    "        return 'Currency not supported'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.00719942, 0.00716538, 0.00717103, 0.00713318, 0.00712708,\n",
       "       0.00713216, 0.00713216, 0.00713216, 0.00725426, 0.00724008,\n",
       "       0.00723014, 0.00727273, 0.00723956, 0.00723956, 0.00723956,\n",
       "       0.00718236, 0.00718236, 0.00716795, 0.00719114, 0.00718649,\n",
       "       0.00718649, 0.00718649, 0.00712504, 0.00711997, 0.00708617,\n",
       "       0.0070497 , 0.00703284, 0.00703284, 0.00703284, 0.00704275,\n",
       "       0.00703383, 0.00703136, 0.00699105, 0.00699056, 0.00699056,\n",
       "       0.00699056, 0.00702839, 0.00708015, 0.00706664, 0.00704672,\n",
       "       0.00710379, 0.00710379, 0.00710379, 0.00712504, 0.00716486,\n",
       "       0.0071449 , 0.00713725, 0.00710379, 0.00710379, 0.00710379,\n",
       "       0.00708667, 0.00706165, 0.00709673, 0.00714898, 0.00718856,\n",
       "       0.00718856, 0.00718856, 0.00725847, 0.00723694, 0.00721709])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "input_curr = 'JPY'\n",
    "\n",
    "rates_df[input_curr].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 USD       JPY       GBP\n",
       "2006-01-01  0.847673  0.007199  1.459215\n",
       "2006-01-02  0.845594  0.007165  1.456664\n",
       "2006-01-03  0.842105  0.007171  1.455075\n",
       "2006-01-04  0.827609  0.007133  1.453172\n",
       "2006-01-05  0.827267  0.007127  1.451800"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>USD</th>\n      <th>JPY</th>\n      <th>GBP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2006-01-01</th>\n      <td>0.847673</td>\n      <td>0.007199</td>\n      <td>1.459215</td>\n    </tr>\n    <tr>\n      <th>2006-01-02</th>\n      <td>0.845594</td>\n      <td>0.007165</td>\n      <td>1.456664</td>\n    </tr>\n    <tr>\n      <th>2006-01-03</th>\n      <td>0.842105</td>\n      <td>0.007171</td>\n      <td>1.455075</td>\n    </tr>\n    <tr>\n      <th>2006-01-04</th>\n      <td>0.827609</td>\n      <td>0.007133</td>\n      <td>1.453172</td>\n    </tr>\n    <tr>\n      <th>2006-01-05</th>\n      <td>0.827267</td>\n      <td>0.007127</td>\n      <td>1.451800</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "rates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            val\n",
       "2006-01-01 -1.0\n",
       "2006-01-02  0.0\n",
       "2006-01-03  1.0\n",
       "2006-01-04  0.5\n",
       "2006-01-05  2.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2006-01-01</th>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>2006-01-02</th>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2006-01-03</th>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2006-01-04</th>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2006-01-05</th>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "test_mul = pd.DataFrame()\n",
    "test_mul['val'] = [-1, 0, 1, 0.5, 2]\n",
    "test_mul['Date'] = rates_df.head().index\n",
    "\n",
    "test_mul=test_mul.set_index(pd.DatetimeIndex(test_mul['Date'].values))\n",
    "test_mul.drop(columns=['Date'],axis=1, inplace=True)\n",
    "\n",
    "test_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-1. ],\n",
       "       [ 0. ],\n",
       "       [ 1. ],\n",
       "       [ 0.5],\n",
       "       [ 2. ]])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "test_mul.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 USD       JPY       GBP\n",
       "2006-01-01  0.847673  0.007199  1.459215\n",
       "2006-01-02  0.845594  0.007165  1.456664\n",
       "2006-01-03  0.842105  0.007171  1.455075\n",
       "2006-01-04  0.827609  0.007133  1.453172\n",
       "2006-01-05  0.827267  0.007127  1.451800"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>USD</th>\n      <th>JPY</th>\n      <th>GBP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2006-01-01</th>\n      <td>0.847673</td>\n      <td>0.007199</td>\n      <td>1.459215</td>\n    </tr>\n    <tr>\n      <th>2006-01-02</th>\n      <td>0.845594</td>\n      <td>0.007165</td>\n      <td>1.456664</td>\n    </tr>\n    <tr>\n      <th>2006-01-03</th>\n      <td>0.842105</td>\n      <td>0.007171</td>\n      <td>1.455075</td>\n    </tr>\n    <tr>\n      <th>2006-01-04</th>\n      <td>0.827609</td>\n      <td>0.007133</td>\n      <td>1.453172</td>\n    </tr>\n    <tr>\n      <th>2006-01-05</th>\n      <td>0.827267</td>\n      <td>0.007127</td>\n      <td>1.451800</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "my_df = rates_df.head()\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.84767314, -0.00719942, -1.45921494],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 0.84210526,  0.00717103,  1.45507457],\n",
       "       [ 0.41380452,  0.00356659,  0.72658577],\n",
       "       [ 1.65453342,  0.01425415,  2.90360046]])"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "np.array(test_mul) * np.array(my_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 USD       JPY       GBP\n",
       "2006-01-01 -0.847673 -0.007199 -1.459215\n",
       "2006-01-02  0.000000  0.000000  0.000000\n",
       "2006-01-03  0.842105  0.007171  1.455075\n",
       "2006-01-04  0.413805  0.003567  0.726586\n",
       "2006-01-05  1.654533  0.014254  2.903600"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>USD</th>\n      <th>JPY</th>\n      <th>GBP</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2006-01-01</th>\n      <td>-0.847673</td>\n      <td>-0.007199</td>\n      <td>-1.459215</td>\n    </tr>\n    <tr>\n      <th>2006-01-02</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2006-01-03</th>\n      <td>0.842105</td>\n      <td>0.007171</td>\n      <td>1.455075</td>\n    </tr>\n    <tr>\n      <th>2006-01-04</th>\n      <td>0.413805</td>\n      <td>0.003567</td>\n      <td>0.726586</td>\n    </tr>\n    <tr>\n      <th>2006-01-05</th>\n      <td>1.654533</td>\n      <td>0.014254</td>\n      <td>2.903600</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "pd.DataFrame(np.array(test_mul) * np.array(my_df),columns=rates_df.columns,index=my_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime(2006,1,1).date()\n",
    "print(start_date)\n",
    "end_date = (datetime.today() - timedelta(1)).date()\n",
    "print(end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of dates\n",
    "dates = []\n",
    "for i in range((end_date - start_date).days + 1):\n",
    "    dates.append((start_date + timedelta(i)))\n",
    "dates[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df = pd.DataFrame()\n",
    "rates_df['Date'] = dates\n",
    "rates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of dates\n",
    "dates = []\n",
    "for i in range(365 * num_years):\n",
    "    dates.append((start + timedelta(i)).date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example call of FX rate API\n",
    "t = datetime(2021, 3, 27)\n",
    "get_rate(\"EUR\", \"USD\", t)\n",
    "# 1.1782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-generated rates csv, can skip rest of section (dev)\n",
    "rates_df = pd.read_csv(\"rates.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time interval of FX rates\n",
    "num_years = 1\n",
    "end = datetime.today()\n",
    "start = end - timedelta(365 * num_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of dates\n",
    "dates = []\n",
    "for i in range(365 * num_years):\n",
    "    dates.append((start + timedelta(i)).date() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df = pd.DataFrame()\n",
    "rates_df['Date'] = dates\n",
    "rates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "\n",
    "rates_USD = []\n",
    "for date in dates:\n",
    "    rates_USD.append(get_rate('USD','EUR', date))\n",
    "print(rates_USD[:10])\n",
    "\n",
    "rates_JPY = []\n",
    "for date in dates:\n",
    "    rates_JPY.append(get_rate('JPY','EUR', date))\n",
    "print(rates_JPY[:10])\n",
    "\n",
    "rates_GBP = []\n",
    "for date in dates:\n",
    "    rates_GBP.append(get_rate('GBP','EUR', date))\n",
    "print(rates_GBP[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_df['Rate'] = rates\n",
    "rates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dates as index\n",
    "rates_df=rates_df.set_index(pd.DatetimeIndex(rates_df['Date'].values))\n",
    "rates_df.drop(columns=['Date'],axis=1, inplace=True)\n",
    "rates_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving down `rates_df` to speed up dev\n",
    "#rates_df.to_csv('rates.csv',index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily price of USD in EUR\n",
    "rates_df.plot(title='EUR/USD')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Portfolio Optimization through mean-variance analysis](https://www.machinelearningplus.com/machine-learning/portfolio-optimization-python-example/)\n",
    "\n",
    "## 1. What is portfolio optimization?\n",
    "Portfolio optimization is the process of creating a portfolio of assets, for which your investment has the maximum return and minimum risk.\n",
    "\n",
    "## 2. What does a portfolio mean?\n",
    "An investor’s portfolio basically is his/her investment in different kinds of assets from different companies.\n",
    "\n",
    "For example, if you have investments in 3 companies, say, Google, Amazon and Tesla, then these 3 companies make up your investment portfolio.\n",
    "\n",
    "But how do you invest in a company? You do so by purchasing assets of that company.\n",
    "\n",
    "## 3. What are assets, returns and risk?\n",
    "Assets are of various kinds. An asset is what you would purchase if you want to invest in a company.\n",
    "\n",
    "These include, but are not limited to:\n",
    "- Bonds\n",
    "- Stocks\n",
    "- Cash\n",
    "- Real Estate\n",
    "Usually when you build a portfolio, it is advisable to diversify your assets, or purchase different kinds of assets from different companies. For all assets, you will get a profit after a specified period of time. However, the profit may not be the same for each investment you make.\n",
    "\n",
    "This profit is what we call returns.\n",
    "\n",
    "For example, you will get returns from stocks when it’s market value goes up and similarly you will get returns from cash in form of interest.\n",
    "\n",
    "But what if the company whose stocks you have purchased goes bankrupt?\n",
    "\n",
    "This will lead to its stocks crashing in the share market and instead of gaining profits, you will also lose your capital investment.\n",
    "\n",
    "This is what is called risk of investment.\n",
    "\n",
    "Another aspect of risk is the fluctuations in the asset value. For certain assets, its value is highly volatile, that is, the value increases when the market goes up, and drops accordingly. Whereas certain other assets, like bonds and certain steady stocks, are relatively more resistant to market conditions, but may give lesser returns compared to high risk ones.\n",
    "\n",
    "A good portfolio is one which gives us maximum return on our investment for minimum risk, as discussed earlier.\n",
    "\n",
    "The next question is, how do we decide out of an infinite possible combinations for portfolios, the one which is optimum?\n",
    "\n",
    "## 4. Modern Portfolio Theory (MPT)\n",
    "Modern Portfolio Theory, or also known as mean-variance analysis is a mathematical process which allows the user to maximize returns for a given risk level.\n",
    "\n",
    "It was formulated by H. Markowitz and while it is not the only optimization technique known, it is the most widely used.\n",
    "\n",
    "MPT assumes that all investors are risk-averse, i.e, if there is a choice between low risk and high risk portfolios with the same returns, an investor will choose one with the low risk.\n",
    "\n",
    "So, what is the MPT all about?\n",
    "\n",
    "MPT encourages diversification of assets. It says that a high variance asset A if combined with diverse assets B and C, where A, B and C have little to no correlation, can give us a portfolio with low variance on returns.\n",
    "\n",
    "This is the crux of the Modern Portfolio Theory.\n",
    "\n",
    "## 5. What is Efficient Frontier?\n",
    "We know every asset in a portfolio has its own rate expected returns and risks. It is possible to create multiple combinations of assets that can provide high returns for a pre-defined risk level.\n",
    "\n",
    "Likewise, there can be multiple portfolios that give lowest risk for a pre-defined expected return.\n",
    "\n",
    "Efficient frontier is a graph with ‘returns’ on the Y-axis and ‘volatility’ on the X-axis. It shows the set of optimal portfolios that offer the highest expected return for a given risk level or the lowest risk for a given level of expected return.\n",
    "\n",
    "Portfolios that lie outside the efficient frontier are sub-optimal because they do not provide either enough return for the level of risk or have a higher risk for the defined rate of return.\n",
    "\n",
    "We will revisit this with an example again.\n",
    "\n",
    "Now that you understand the term of portfolio optimization, let’s see how its actually implemented.\n",
    "\n",
    "## 6. Fundamental terms in portfolio optimization\n",
    "There are some statistical terms required in optimization process without which an optimal portfolio can’t be defined. Don’t worry, I will simplify it and make it easy and clear.\n",
    "\n",
    "We will go through each one through an example.\n",
    "\n",
    "In this example, we are considering a portfolio made up of stocks from just 4 companies, Microsoft, Apple, Tesla and Facebook.\n",
    "\n",
    "### Step 1: Pull the stock price data\n",
    "\n",
    "We have this data from the data bases earlier in this script, so we can connect to our nasdaq database which has the closing price of company’s stock on the given day and pull this data for these stocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_Nasdaq=dmf.connectAndLoadDb('NASDAQ')\n",
    "\n",
    "#set dates as index\n",
    "df_Nasdaq=df_Nasdaq.set_index(pd.DatetimeIndex(df_Nasdaq['Date'].values))\n",
    "df_Nasdaq.drop(columns=['Date'],axis=1, inplace=True)\n",
    "\n",
    "#Stock list Tickers we want Microsoft, Apple, Tesla and Facebook\n",
    "l_stocks=['AAPL', 'MSFT', 'TSLA', 'FB']\n",
    "\n",
    "df_example=df_Nasdaq[l_stocks]\n",
    "df_example.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate percentage change in stock prices\n",
    "\n",
    "Next, we calculate the percentage change in stock prices of tesla everyday. You will notice that that we take the log of percentage change.\n",
    "\n",
    "But take log?  The reason for this is that log of the returns is time additive.\n",
    "\n",
    "That is, $ log(r_{13}) = log(r_{12}) + log(r_{23}) $\n",
    "\n",
    "For example:,\n",
    "If $ p_1 = 100,\\quad p_2 = 110,\\quad p_3 = 120  $\n",
    "where $ p_1 $ is price of stock in time 1\n",
    "\n",
    "Then:\n",
    "\n",
    "$ log(r_{12}) = ln(\\frac{p_2}{p_1}) = ln(\\frac{110}{100}) = 9.53%, $\n",
    "\n",
    "$ log(r_{23}) = ln(\\frac{120}{110}) = 8.7% $ and\n",
    "\n",
    "$ log(r_{13}) = log(r_{12}) + log(r_{23}) = 9.53 + 8.7 = 18.23%, $  which is same as $ ln(\\frac{120}{100}) $.\n",
    "\n",
    "This means a log change of +0.1 today and then -0.1 tomorrow will give you the same value of stock as yesterday. This is not true if you simply compute percentage change.\n",
    "\n",
    "It is common practice in portfolio optimization to take log of returns for calculations of covariance and correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of percentage change\n",
    "tesla = df_example['TSLA'].pct_change().apply(lambda x: np.log(1+x))\n",
    "tesla.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance\n",
    "The variance in prices of stocks of Tesla are an important indicator of how volatile this investment will be (how returns can fluctuate).\n",
    "\n",
    "It can be calculated for each company by using built in .var() function. Under the hood, the formula implemented by this function is given by:\n",
    "$$ s^2 = \\sum_{i=1}^N (x_i – \\bar{x})^2 / N-1 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "var_tesla = tesla.var()\n",
    "var_tesla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly for Facebook,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of Percentage change for Facebook\n",
    "fb = df_example['FB'].pct_change().apply(lambda x: np.log(1+x))\n",
    "\n",
    "# Variance\n",
    "var_fb = fb.var()\n",
    "var_fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volatility\n",
    "Volatility is measured as the standard deviation of a company’s stock.\n",
    "\n",
    "If you carefully look at the formula for standard deviation, you will understand that it is just the square root of variance.\n",
    "\n",
    "$$ s = \\sqrt{ \\sum_{i=1}^N (x_i – \\bar{x})^2 / N-1} $$\n",
    "\n",
    "But volatility for the annual standard deviation. What we get from square root of variance is the daily standard deviation. To convert it to annual standard deviation we multiply the variance by 250.\n",
    "\n",
    "250 is used because there are 250 trading days in a year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility\n",
    "tesla_vol = np.sqrt(var_tesla * 250)\n",
    "fb_vol = np.sqrt(var_fb * 250)\n",
    "tesla_vol, fb_vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility of our stocks plotted\n",
    "df_example.pct_change().apply(lambda x: np.log(1+x)).std().apply(lambda x: x*np.sqrt(250)).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "Covariance measures the directional relationship between the returns on two assets.\n",
    "\n",
    "A positive covariance means that returns of the two assets move together while a negative covariance means they move inversely. Risk and volatility can be reduced in a portfolio by pairing assets that have a negative covariance.\n",
    "\n",
    "We can calculate the covariance of Tesla and Facebook by using the .cov() function.\n",
    "\n",
    "You can notice that there is small positive covariance between Tesla and Facebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of Percentage change\n",
    "test1 = df_example.pct_change().apply(lambda x: np.log(1+x))\n",
    "# Covariance\n",
    "test1['TSLA'].cov(test1['FB'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "Correlation, in the finance and investment industries, is a statistic that measures the degree to which two securities move in relation to each other. Correlations are used in advanced portfolio management, computed as the correlation coefficient, which has a value that must fall between -1.0 and +1.0.\n",
    "\n",
    "You can think of correlation as a scaled version of covariance, where the values are restricted to lie between -1 and +1.\n",
    "\n",
    "A correlation of -1 means negative relation, i.e, if correlation between Asset A and Asset B is -1, if Asset A increases, Asset B decreases.\n",
    "\n",
    "A correlation of +1 means positive relation, i.e, if correlation between Asset A and Asset B is 1, if Asset A increases, Asset B increases.\n",
    "\n",
    "A correlation of 0 means no relation, i.e, if correlation between Asset A and Asset B is 0, they dont have any effect on each other.\n",
    "\n",
    "This is calculated using the .corr() function.\n",
    "\n",
    "In line with the covariance, the correlation between Tesla and Facebook is also positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1['TSLA'].corr(test1['FB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Returns\n",
    "Expected returns of an asset are simply the mean of percentage change in its stock prices. So, the value of expected return we obtain here are daily expected returns.\n",
    "\n",
    "For a yearly expected return value, you will need to resample the data year-wise, as you will see further.\n",
    "\n",
    "For expected returns, you need to define weights for the assets choosen.\n",
    "\n",
    "In simpler terms, this means you need to decide what percentage of your total money to you want to hold in each company’s stock.\n",
    "\n",
    "Usually this decision is done by using the optimization techniques we will discuss later but for now we will consider random weights.\n",
    "\n",
    "First, let’s compute the log of percentage change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = df_example.pct_change().apply(lambda x: np.log(1+x))\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights\n",
    "Let’s define an array of random weights for the purpose of calculation. These weights will represent the percentage allocation of investments between these two stocks. They must add up to 1.\n",
    "\n",
    "So, the problem of portfolio optimization is nothing but to find the optimal values of weights that maximizes expected returns while minimizing the risk (standard deviation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weights for allocation\n",
    "w = [0.2,0.2,0.3, 0.3]\n",
    "e_r_ind = test2.mean()\n",
    "e_r_ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total expected return for a portfolio is given by:\n",
    "\n",
    "$$ E(R_p) = w_1E(R_1) + w_2E(R_2) + ….. w_nE(R_n)$$\n",
    "\n",
    "Thus, $ e_r $, or total expected return can be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total expected return\n",
    "e_r = (e_r_ind*w).sum()\n",
    "e_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Building an optimal risky portfolio\n",
    "Now that you have gone through the building blocks of portfolio optimization, it is time to create an optimal portfolio using the same concepts.\n",
    "\n",
    "We will be using stocks from 4 companies, namely, Microsoft, Apple, Tesla and Facebook for a period of 5 years.\n",
    "\n",
    "You will learn to calculate the weights of assets for each one. Then, we will calculate the expected returns, minimum variance portfolio, optimal risky portfolio and efficient frontier. You will also learn a new term called Sharpe Ratio.\n",
    "\n",
    "Let’s get started by pulling the required asset data from our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_Nasdaq=dmf.connectAndLoadDb('NASDAQ')\n",
    "\n",
    "#set dates as index\n",
    "df_Nasdaq=df_Nasdaq.set_index(pd.DatetimeIndex(df_Nasdaq['Date'].values))\n",
    "df_Nasdaq.drop(columns=['Date'],axis=1, inplace=True)\n",
    "\n",
    "#Stock list Tickers we want Microsoft, Apple, Tesla and Facebook\n",
    "l_stocks=['AAPL', 'MSFT', 'TSLA', 'FB']\n",
    "\n",
    "df_example=df_Nasdaq[l_stocks]\n",
    "df_example=df_example['2015-01-01':'2020-01-01']\n",
    "df_example.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Covariance and Correlation matrix\n",
    "The first step is to obtain a covariance and correlation matrix to understand how different assets behave with respect to each other. When we had a 2 asset portfolio, we directly plugged in the names of the assets into .cov() and .corr() functions.\n",
    "\n",
    "In this case, we will need a matrix for better visualisation. This is also achieved by using the same 2 functions on our dataframe df.\n",
    "\n",
    "Note that we perform necessary operations to display log change in prices of stocks each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log of percentage change\n",
    "cov_matrix = df_example.pct_change().apply(lambda x: np.log(1+x)).cov()\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance between Apple and Apple, or Tesla and Tesla is the variance of that asset.\n",
    "\n",
    "The next step is to create the correlation matrix. Correlation ranges from -1 to 1.\n",
    "\n",
    "Trivialy, an asset always has a perfectly positive correlation of 1 with itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df_example.pct_change().apply(lambda x: np.log(1+x)).corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Variance\n",
    "The formula for calculating portfolio variance differs from the usual formula of variance. It looks like this:\n",
    "\n",
    "$$\\sigma^2(Rp) = \\sum{i=1}^{n} \\sum_{j=1}^{n} w_i w_j COV(R_i, R_j) $$\n",
    "Here, $ w_i $ and $ w_j $ denote weights of all assets from 1 to n (in our case from 1 to 4) and $ COV(R_i, R_j) $ is the covariance of the two assets denoted by i and j.\n",
    "The simplest way to do this complex calculation is defining a list of weights and multiplying this list horizontally and vertically with our covariance matrix.\n",
    "\n",
    "For this purpose, let’s define a random list of weights for all 4 assets. Remember that sum of weights should always be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly weighted portfolio's variance\n",
    "w = {'AAPL': 0.1, 'MSFT': 0.2, 'TSLA': 0.5, 'FB': 0.2}\n",
    "port_var = cov_matrix.mul(w, axis=0).mul(w, axis=1).sum().sum()\n",
    "port_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have found the portfolio variance. But for truly optimizing the portfolio, we cant plug in random weights. We will need to calculate it according to what gives us maximum expected returns.\n",
    "\n",
    "### 9. Portfolio expected returns\n",
    "The mean of returns (given by change in prices of asset stock prices) give us the expected returns of that asset.\n",
    "The sum of all individual expected returns further multiplied by the weight of assets give us expected return for the portfolio.\n",
    "\n",
    "Note that we use the resample() function to get yearly returns. The argument to function, ‘Y’, denotes yearly.\n",
    "If we dont perform resampling, we will get daily returns, like you saw earlier in the ‘Fundamental Terms’ section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly returns for individual companies\n",
    "ind_er = df_example.resample('Y').last().pct_change().mean()\n",
    "ind_er"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio expected returns\n",
    "w = [0.1, 0.2, 0.5, 0.2]\n",
    "port_er = (w*ind_er).sum()\n",
    "port_er"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the efficient frontier\n",
    "This is the aim of going through all the topics above, to plot the efficient frontier. Efficient frontier is a graph with ‘returns’ on the Y-axis and ‘volatility’ on the X-axis. It shows us the maximum return we can get for a set level of volatility, or conversely, the volatility that we need to accept for certain level of returns.\n",
    "\n",
    "Below, you can see the calculations and code for finding the optimal weights of assets and plotting the efficient frontier for given portfolio.\n",
    "But first, lets take a look at the volatiltilty and returns of individual assets for a better understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volatility is given by the annual standard deviation. We multiply by 250 because there are 250 trading days/year.\n",
    "ann_sd = df_example.pct_change().apply(lambda x: np.log(1+x)).std().apply(lambda x: x*np.sqrt(250))\n",
    "ann_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = pd.concat([ind_er, ann_sd], axis=1) # Creating a table for visualising returns and volatility of assets\n",
    "assets.columns = ['Returns', 'Volatility']\n",
    "assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tesla has the maximum risk attached but has low returns. Apple has low risk and high return rates. Facebook is somewhere in the middle.\n",
    "\n",
    "Next, to plot the graph of efficient frontier, we need run a loop. In each iteration, the loop considers different weights for assets and calculates the return and volatility of that particular portfolio combination.\n",
    "\n",
    "We run this loop a 10,000 times.\n",
    "\n",
    "To get random numbers for weights, we use the np.random.random() function. But remember that the sum of weights must be 1, so we divide those weights by their cumulative sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ret = [] # Define an empty array for portfolio returns\n",
    "p_vol = [] # Define an empty array for portfolio volatility\n",
    "p_weights = [] # Define an empty array for asset weights\n",
    "\n",
    "num_assets = len(df_example.columns)\n",
    "num_portfolios = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for portfolio in range(num_portfolios):\n",
    "    weights = np.random.random(num_assets)\n",
    "    weights = weights/np.sum(weights)\n",
    "    p_weights.append(weights)\n",
    "    returns = np.dot(weights, ind_er) # Returns are the product of individual expected returns of asset and its \n",
    "                                      # weights \n",
    "    p_ret.append(returns)\n",
    "    var = cov_matrix.mul(weights, axis=0).mul(weights, axis=1).sum().sum()# Portfolio Variance\n",
    "    sd = np.sqrt(var) # Daily standard deviation\n",
    "    ann_sd = sd*np.sqrt(250) # Annual standard deviation = volatility\n",
    "    p_vol.append(ann_sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Returns':p_ret, 'Volatility':p_vol}\n",
    "\n",
    "for counter, symbol in enumerate(df_example.columns.tolist()):\n",
    "    #print(counter, symbol)\n",
    "    data[symbol+' weight'] = [w[counter] for w in p_weights]\n",
    "    \n",
    "portfolios  = pd.DataFrame(data)\n",
    "portfolios.head() # Dataframe of the 10000 portfolios created    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that there are a number of portfolios with different weights, returns and volatility. Plotting the returns and volatility from this dataframe will give us the efficient frontier for our portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot efficient frontier\n",
    "portfolios.plot.scatter(x='Volatility', y='Returns', marker='o', s=10, alpha=0.2, grid=True, figsize=[10,10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to read the Efficient Frontier?\n",
    "Each point on the line (left edge) represents an optimal portfolio of stocks that maximises the returns for any given level of risk.\n",
    "\n",
    "The point (portfolios) in the interior are sub-optimal for a given risk level. For every interior point, there is another that offers higher returns for the same risk.\n",
    "\n",
    "On this graph, you can also see the combination of weights that will give you all possible combinations:\n",
    "\n",
    "Minimum volatility (left most point)\n",
    "Maximum returns (top most point)\n",
    "And everything in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_vol_port = portfolios.iloc[portfolios['Volatility'].idxmin()]\n",
    "# idxmin() gives us the minimum value in the column specified.                               \n",
    "min_vol_port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum volatility is in a portfolio where the weights of Microsoft, Apple, Tesla and Facebook are 43%, 33%, 6% and 19% respectively. This point can be plotted on the efficient frontier graph as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the minimum volatility portfolio\n",
    "plt.subplots(figsize=[10,10])\n",
    "plt.scatter(portfolios['Volatility'], portfolios['Returns'],marker='o', s=10, alpha=0.3)\n",
    "plt.scatter(min_vol_port[1], min_vol_port[0], color='r', marker='*', s=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The red star denotes the most efficient portfolio with minimum volatility.\n",
    "\n",
    "It is worthwhile to note that any point to the right of efficient frontier boundary is a sup-optimal portfolio.\n",
    "\n",
    "We found the portfolio with minimum volatility, but you will notice that the return on this portfolio is pretty low. Any sensible investor wants to maximize his return, even if it is a tradeoff with some level of risk.\n",
    "\n",
    "The question arises that how do we find this optimal risky portfolio and finally optimize our portfolio to the maximum?\n",
    "\n",
    "This is done by using a parameter called the **Sharpe Ratio**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharpe Ratio\n",
    "The ratio is the average return earned in excess of the risk-free rate per unit of volatility or total risk. Volatility is a measure of the price fluctuations of an asset or portfolio.\n",
    "\n",
    "The risk-free rate of return is the return on an investment with zero risk, meaning it’s the return investors could expect for taking no risk.\n",
    "\n",
    "The optimal risky portfolio is the one with the highest Sharpe ratio. The formula for this ratio is:\n",
    "\n",
    "$ R_p $ = return of the portfolio,$ \\quad R_f =$ Risk free rate, $\\quad 𝜎_p =$ standard deviation of the portfolio   \n",
    "\n",
    "Sharpe Ratio = $ \\frac{R_p - R_f}{𝜎_p} $   \n",
    "Below is the code for finding out portfolio with maximum Sharpe Ratio. This portfolio is the optimized portfolio that we wanted to find. We define the risk-free rate to be 1% or 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Risky Portfolio\n",
    "An optimal risky portfolio can be considered as one that has highest Sharpe ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the optimal portfolio\n",
    "rf = 0.01 # risk factor\n",
    "optimal_risky_port = portfolios.iloc[((portfolios['Returns']-rf)/portfolios['Volatility']).idxmax()]\n",
    "optimal_risky_port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can notice that while the difference in risk between minimum volatility portfolio and optimal risky portfolio is just 1%, the difference in returns is 4%.\n",
    "We can plot this point too on the graph of efficient frontier:\n",
    "The green star represents the optimal risky portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting optimal portfolio\n",
    "plt.subplots(figsize=(10, 10))\n",
    "plt.scatter(portfolios['Volatility'], portfolios['Returns'],marker='o', s=10, alpha=0.3)\n",
    "plt.scatter(min_vol_port[1], min_vol_port[0], color='r', marker='*', s=500)\n",
    "plt.scatter(optimal_risky_port[1], optimal_risky_port[0], color='g', marker='*', s=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how would have this portfolio actually perfomed this is something i want to expand on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example=df_Nasdaq[l_stocks]\n",
    "df_example=df_example['2020-01-01':'2021-01-04']\n",
    "df_example.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights as advised above returns\n",
    "w = [0.474041, 0.515592, 0.002323, 0.008043]\n",
    "\n",
    "#actual log of pct change\n",
    "actual_performance =df_example.pct_change().apply(lambda x: np.log(1+x)).sum()\n",
    "\n",
    "#now we have summed we inverse the log & use the advised weights & Sum to get the portfolios performnce\n",
    "port_performance=((actual_performance.apply(lambda x: math.exp(x)-1))*w).sum()\n",
    "\n",
    "print(\"Expected Return: \",round(optimal_risky_port[0],2))\n",
    "print(\"Actual Return:   \",round(port_performance,2))\n",
    "pd.DataFrame([optimal_risky_port[0],((actual_performance.apply(lambda x: math.exp(x)-1))*w).sum()],index=['Expected Return','Actual Return']).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for 2020 our optimal portfolio based off the 2015 - 2019 data outperformed our expected returns by **21% !!!!!!!!!!!!!!**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this approach at scale:\n",
    "We need to use a library thats built for this to do this at scale at speed: [PyPortfolioOpt](https://pyportfolioopt.readthedocs.io/en/latest/index.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_example=df_Nasdaq[l_stocks]\n",
    "df_example=df_example['2015-01-01':'2020-01-01']\n",
    "df_example.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Calculate expected annulised returns & annual sample covariance matrix of the daily asset\n",
    "example_mu = expected_returns.mean_historical_return(df_example)\n",
    "example_S = risk_models.sample_cov(df_example)\n",
    "print(example_mu)\n",
    "example_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Optomise for maximal Sharpe ratio\n",
    "example_ef= EfficientFrontier(example_mu, example_S) #Create the Efficient Frontier Object\n",
    "example_weights = example_ef.max_sharpe()\n",
    "example_cl_weights= example_ef.clean_weights()\n",
    "print(example_cl_weights)\n",
    "print('')\n",
    "example_ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ef = EfficientFrontier(example_mu, example_S, weight_bounds=(None, None))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plotting.plot_efficient_frontier(ef, ax=ax, show_assets=False)\n",
    "\n",
    "# Find the tangency portfolio\n",
    "ef.max_sharpe()\n",
    "ret_tangent, std_tangent, _ = ef.portfolio_performance()\n",
    "ax.scatter(std_tangent, ret_tangent, marker=\"*\", s=100, c=\"r\", label=\"Max Sharpe\")\n",
    "\n",
    "# Generate random portfolios\n",
    "n_samples = 10000\n",
    "w = np.random.dirichlet(np.ones(len(example_mu)), n_samples)\n",
    "rets = w.dot(example_mu)\n",
    "stds = np.sqrt(np.diag(w @ example_S @ w.T))\n",
    "sharpes = rets / stds\n",
    "ax.scatter(stds, rets, marker=\".\", c=sharpes, cmap=\"viridis_r\")\n",
    "\n",
    "# Output\n",
    "ax.set_title(\"Efficient Frontier with random portfolios\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the discrete allocation of each share per stock\n",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "\n",
    "portfolio_val = 1000\n",
    "latest_prices=get_latest_prices(df_example)\n",
    "weights=example_cl_weights\n",
    "da=DiscreteAllocation(weights,latest_prices,total_portfolio_value=portfolio_val)\n",
    "allocation, leftover = da.lp_portfolio()\n",
    "\n",
    "print('Discrete allocation  :', allocation)\n",
    "print('Funds Remaining:', leftover)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}